{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "name_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMLvpWuEXpwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "ec409612-f4f8-4e33-be96-3cfebf528d3c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "%pylab\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,auc,roc_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,Activation,Dropout,LSTM,Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using matplotlib backend: agg\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUYl_a_MYRaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f388f654-6d5f-4d0b-8725-d1ffe1524b80"
      },
      "source": [
        "#data stored in a csv file hosted on a public GitHub repo.\n",
        "csv_url = \"https://raw.githubusercontent.com/Sly1029/Twitter-Android/master/names_dataset.csv\"\n",
        "df = pd.read_csv(csv_url,sep=\",\")\n",
        "\n",
        "\n",
        "names = df['name'].apply(lambda x:x.lower())\n",
        "females =  (df.loc[df['sex']=='F']['sex'])\n",
        "males = (df.loc[df['sex']=='M']['sex'])\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>name</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Mary</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Anna</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Emma</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Elizabeth</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Minnie</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index       name sex\n",
              "0      0       Mary   F\n",
              "1      1       Anna   F\n",
              "2      2       Emma   F\n",
              "3      3  Elizabeth   F\n",
              "4      4     Minnie   F"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8svOjDL9twUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualizing length of names\n",
        "plt.figure(figsize(12,8))\n",
        "plt.hist([len(n) for n in names], bins=36)\n",
        "plt.title(\"Length of names\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcf3ax-3up-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54f23998-f6b6-4e7f-f096-67a808775375"
      },
      "source": [
        "#class imbalance\n",
        "print(\"Females\",len(females.to_numpy()))\n",
        "print(\"Males\",len(males.to_numpy()))\n",
        "\n",
        "#RESOLVE class imbalance if really needed in future. Might not be an issue with LSTM."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Females 60600\n",
            "Males 34425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSo6gZpRvv7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cf3619ef-d810-4f98-ce55-b865c169295c"
      },
      "source": [
        "#creating vocab\n",
        "vocab = set(''.join([str(i) for i in names]))\n",
        "vocab.add(\"-\")\n",
        "vocab.add(\".\")\n",
        "\n",
        "#\"-\" denotes END\n",
        "#'.' denotes NULL CHAR\n",
        "vocab = list(vocab)\n",
        "vocab.sort()\n",
        "print(vocab)\n",
        "print(len(vocab))\n",
        "\n",
        "mapping = dict((c,i) for i,c in enumerate(vocab))\n",
        "print(mapping)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['-', '.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "28\n",
            "{'-': 0, '.': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDnt11tvjO1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f79d1b13-7342-4f51-e71d-ef7316a2e3a7"
      },
      "source": [
        "#vectorizing y\n",
        "data_y = []\n",
        "max_len = 10\n",
        "\n",
        "my_dict = {'F':0,'M':1}\n",
        "df = df.replace(my_dict)\n",
        "\n",
        "final_Y = []\n",
        "y_vals = df['sex']\n",
        "data_Y = y_vals.to_numpy()\n",
        "\n",
        "for i in data_Y:\n",
        "  if i == 0:\n",
        "    final_Y.append([1,0])\n",
        "  else:\n",
        "    final_Y.append([0,1])\n",
        "\n",
        "final_Y = np.asarray(final_Y)\n",
        "final_Y.shape\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95025, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_u5k-XQ_-VO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "309d827b-9ffb-4bbd-c0c4-7023d3a841c9"
      },
      "source": [
        "#vectorizing x\n",
        "\n",
        "\n",
        "final_X = []\n",
        "\n",
        "for words in names.values:\n",
        "  final_mapping = []\n",
        "  trunc_name = str(words)[0:max_len]\n",
        "  #print(trunc_name)\n",
        "  tmp = list(trunc_name)\n",
        "  for items in tmp:\n",
        "    word = []\n",
        "    for index in range(30):\n",
        "      if index < len(items):\n",
        "        word.append(mapping[items[index]])\n",
        "        continue\n",
        "      if index==len(items):\n",
        "        word.append(mapping[\"-\"])\n",
        "        continue\n",
        "      else:\n",
        "        word.append(mapping[\".\"])\n",
        "        continue\n",
        "\n",
        "    b = np.zeros((28,))\n",
        "    final_mapping.append(np.eye(28)[word][0])\n",
        "  a = np.zeros((28,))\n",
        "  index = mapping['-']\n",
        "  a[index] = 1\n",
        "  final_mapping.append(a)\n",
        "  #final_X.append(np.asarray(final_mapping))\n",
        "  filled = final_mapping[-1]\n",
        "  #print(filled)\n",
        "  while len(final_mapping)<=10:\n",
        "    a = np.zeros((28,))\n",
        "    index = mapping['.']\n",
        "    a[index] = 1\n",
        "    final_mapping.append(a)\n",
        "  final_X.append(np.asarray(final_mapping))\n",
        "  #print(np.asarray(final_mapping))\n",
        "\n",
        "final_X = np.asarray(final_X)\n",
        "\n",
        "final_X.shape\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95025, 11, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3ND8PQFrVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29d1391f-ba50-4146-ca69-2bafb23e469a"
      },
      "source": [
        "#only use this crap for logistic regression in sklearn\n",
        "very_final_X = []\n",
        "for index,items in enumerate(final_X):\n",
        "  final_items = np.zeros(28,)\n",
        "  for more in items:\n",
        "    final_items = final_items + more\n",
        "    #final_items = sum(more,final_items)\n",
        "  very_final_X.append(final_items)\n",
        "  #final_X[index] = np.zeros(28,)\n",
        "  #final_X[index] = final_items \n",
        "\n",
        "very_final_X = np.asarray(very_final_X)\n",
        "print(very_final_X[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 6. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d252e546-8d55-41d5-9bc9-48b33b0f29af",
        "id": "pGm0fN2w1cHS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#vectorizing y\n",
        "data_y = []\n",
        "max_len = 10\n",
        "\n",
        "my_dict = {'F':0,'M':1}\n",
        "df = df.replace(my_dict)\n",
        "\n",
        "final_Y = []\n",
        "y_vals = df['sex']\n",
        "data_Y = y_vals.to_numpy()\n",
        "\n",
        "for i in data_Y:\n",
        "  if i == 0:\n",
        "    final_Y.append([1,0])\n",
        "  else:\n",
        "    final_Y.append([0,1])\n",
        "\n",
        "final_Y = np.asarray(data_Y)\n",
        "final_Y.shape\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95025,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg5oiPm5QK1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#logistic regression-split\n",
        "X_log_train,X_log_test,y_train,y_test = train_test_split(very_final_X,final_Y,test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTZEiFZBEIaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9bd91ea4-6540-4e33-92af-228bb1437198"
      },
      "source": [
        "#model building - logistic regression\n",
        "logistic_regression = LogisticRegression(solver='lbfgs',penalty='none',fit_intercept=False)\n",
        "logistic_regression.fit(X_log_train,y_train)\n",
        "\n",
        "#training_accuracy\n",
        "train_predictions = logistic_regression.predict(X_log_train)\n",
        "score = accuracy_score(train_predictions,y_train)\n",
        "print(score*100)\n",
        "\n",
        "#test_accuracy\n",
        "test_predictions = logistic_regression.predict(X_log_test)\n",
        "score = accuracy_score(test_predictions,y_test)\n",
        "print(score*100)\n",
        "\n",
        "#params\n",
        "print(logistic_regression.coef_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72.46088725708006\n",
            "71.3564137640745\n",
            "[[ 0.58857223  0.04678496 -1.04497639  0.43164416  0.26131624  0.66172622\n",
            "  -0.79016378  0.5471032   0.46373086 -0.02462423 -0.83470927  0.78316331\n",
            "   0.50625019 -0.13211847  0.51473895  0.01971747  0.1975784   0.38144\n",
            "   0.77008521  0.4106635   0.14508123  0.09254046  0.18922783  0.90189165\n",
            "   0.85288411  0.88135201 -0.84106897  0.49446344]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXROREpk8TiM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "87306777-186e-4f4e-9078-aaa70f168764"
      },
      "source": [
        "#train test split\n",
        "X_train,X_test,y_train,y_test = train_test_split(final_X,final_Y,test_size=0.1)\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "\n",
        "'''\n",
        "X_train = tf.convert_to_tensor(X_train,np.float32)\n",
        "X_test = tf.convert_to_tensor(X_test,np.float32)\n",
        "y_train = tf.convert_to_tensor(y_train,np.float32)\n",
        "y_test = tf.convert_to_tensor(y_test,np.float32)\n",
        "'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX_train = tf.convert_to_tensor(X_train,np.float32)\\nX_test = tf.convert_to_tensor(X_test,np.float32)\\ny_train = tf.convert_to_tensor(y_train,np.float32)\\ny_test = tf.convert_to_tensor(y_test,np.float32)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExHPj9VaTMjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b36a1dfc-53b2-4838-baa6-b0f1d098dbce"
      },
      "source": [
        "#LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(512,return_sequences=True),backward_layer=LSTM(512,return_sequences=True,go_backwards=True),input_shape=(max_len+1,len(vocab))))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(512)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2, activity_regularizer=l2(0.002)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOSY7L-_VANX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
        "mc = ModelCheckpoint('best_model_9.h5', monitor='val_loss', mode='min', verbose=1)\n",
        "reduce_lr_acc = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, min_delta=1e-4, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q93wr4YtVGFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df90b6a1-5541-4eca-ae00-07304505883c"
      },
      "source": [
        "batch_size = 256\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=35,verbose=1, validation_data =(X_test, y_test), callbacks=[callback, mc, reduce_lr_acc])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 85522 samples, validate on 9503 samples\n",
            "Epoch 1/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.4353 - acc: 0.8008\n",
            "Epoch 00001: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 163s 2ms/sample - loss: 0.4353 - acc: 0.8008 - val_loss: 0.3922 - val_acc: 0.8325\n",
            "Epoch 2/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.3701 - acc: 0.8374\n",
            "Epoch 00002: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 163s 2ms/sample - loss: 0.3701 - acc: 0.8374 - val_loss: 0.3577 - val_acc: 0.8500\n",
            "Epoch 3/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.3417 - acc: 0.8535\n",
            "Epoch 00003: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 164s 2ms/sample - loss: 0.3417 - acc: 0.8535 - val_loss: 0.3320 - val_acc: 0.8629\n",
            "Epoch 4/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.3226 - acc: 0.8645\n",
            "Epoch 00004: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 166s 2ms/sample - loss: 0.3226 - acc: 0.8645 - val_loss: 0.3216 - val_acc: 0.8686\n",
            "Epoch 5/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.8728\n",
            "Epoch 00005: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 165s 2ms/sample - loss: 0.3055 - acc: 0.8728 - val_loss: 0.3072 - val_acc: 0.8741\n",
            "Epoch 6/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.2907 - acc: 0.8808\n",
            "Epoch 00006: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 166s 2ms/sample - loss: 0.2907 - acc: 0.8808 - val_loss: 0.3029 - val_acc: 0.8774\n",
            "Epoch 7/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.2753 - acc: 0.8885\n",
            "Epoch 00007: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 167s 2ms/sample - loss: 0.2753 - acc: 0.8885 - val_loss: 0.3071 - val_acc: 0.8740\n",
            "Epoch 8/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.2605 - acc: 0.8962\n",
            "Epoch 00008: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 167s 2ms/sample - loss: 0.2605 - acc: 0.8962 - val_loss: 0.2799 - val_acc: 0.8890\n",
            "Epoch 9/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.2436 - acc: 0.9038\n",
            "Epoch 00009: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 165s 2ms/sample - loss: 0.2435 - acc: 0.9038 - val_loss: 0.2774 - val_acc: 0.8925\n",
            "Epoch 10/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9122\n",
            "Epoch 00010: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 165s 2ms/sample - loss: 0.2274 - acc: 0.9122 - val_loss: 0.2713 - val_acc: 0.8946\n",
            "Epoch 11/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9209\n",
            "Epoch 00011: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 166s 2ms/sample - loss: 0.2091 - acc: 0.9209 - val_loss: 0.2648 - val_acc: 0.8994\n",
            "Epoch 12/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.1892 - acc: 0.9310\n",
            "Epoch 00012: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 167s 2ms/sample - loss: 0.1892 - acc: 0.9310 - val_loss: 0.2654 - val_acc: 0.8994\n",
            "Epoch 13/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9385\n",
            "Epoch 00013: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 167s 2ms/sample - loss: 0.1701 - acc: 0.9385 - val_loss: 0.2684 - val_acc: 0.9002\n",
            "Epoch 14/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9497\n",
            "Epoch 00014: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 172s 2ms/sample - loss: 0.1485 - acc: 0.9497 - val_loss: 0.2658 - val_acc: 0.9034\n",
            "Epoch 15/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9600\n",
            "Epoch 00015: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 169s 2ms/sample - loss: 0.1284 - acc: 0.9600 - val_loss: 0.2777 - val_acc: 0.9059\n",
            "Epoch 16/35\n",
            "85504/85522 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9685\n",
            "Epoch 00016: saving model to best_model_9.h5\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "85522/85522 [==============================] - 166s 2ms/sample - loss: 0.1098 - acc: 0.9684 - val_loss: 0.2949 - val_acc: 0.9035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "36791ce1-eecc-4fd6-8e76-fdb334ef2cce",
        "id": "Uswcfxx6ZGvY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#a function to convert names to vectors for custom testing once the model is trained\n",
        "given_test = [\"ben\",\"john\"]\n",
        "\n",
        "final_X = []\n",
        "\n",
        "def convert_X(X):\n",
        "  for words in X:\n",
        "    words = words.lower()\n",
        "    final_mapping = []\n",
        "    trunc_name = str(words)[0:max_len]\n",
        "    #print(trunc_name)\n",
        "    tmp = list(trunc_name)\n",
        "    for items in tmp:\n",
        "      word = []\n",
        "      for index in range(30):\n",
        "        if index < len(items):\n",
        "          word.append(mapping[items[index]])\n",
        "          continue\n",
        "        if index==len(items):\n",
        "          word.append(mapping[\"-\"])\n",
        "          continue\n",
        "        else:\n",
        "          word.append(mapping[\".\"])\n",
        "          continue\n",
        "\n",
        "      b = np.zeros((28,))\n",
        "      final_mapping.append(np.eye(28)[word][0])\n",
        "    a = np.zeros((28,))\n",
        "    index = mapping['-']\n",
        "    a[index] = 1\n",
        "    final_mapping.append(a)\n",
        "    #final_X.append(np.asarray(final_mapping))\n",
        "    filled = final_mapping[-1]\n",
        "    #print(filled)\n",
        "    while len(final_mapping)<=10:\n",
        "      a = np.zeros((28,))\n",
        "      index = mapping['.']\n",
        "      a[index] = 1\n",
        "      final_mapping.append(a)\n",
        "    final_X.append(np.asarray(final_mapping))\n",
        "    #print(np.asarray(final_mapping))\n",
        "  return np.asarray(final_X)\n",
        "\n",
        "input_list = [\"akash\",\"vivek\",\"John\",\"Laila\",\"Samantha\",\"Rohit\",\"Sam\",\"Jupiter\",\"Shiliqua\",\"Eileen\",\"Kasey\",\"Casey\"]\n",
        "testy = convert_X(input_list)\n",
        "\n",
        "predictions = model.predict(testy)\n",
        "#print(predictions)\n",
        "#print(predictions)\n",
        "\n",
        "\n",
        "#besty = convert_X(X_test)\n",
        "correct = 0\n",
        "total = 0\n",
        "#predictions = model.predict(X_test)\n",
        "for index,items in enumerate(predictions):\n",
        "  total+=1\n",
        "  if items[0] >= items[1]:\n",
        "    if y_test[index][0] == 1:\n",
        "      correct+=1\n",
        "  else:\n",
        "    if y_test[index][1]==1:\n",
        "      correct+=1\n",
        "\n",
        "acc = correct/total * 100\n",
        "    \n",
        "for index,items in enumerate(input_list):\n",
        "  if predictions[index][0] > predictions[index][1]:\n",
        "    print('Girl ',end=\"\")\n",
        "\n",
        "  if predictions[index][1]>predictions[index][0]:\n",
        "    print('Boy ',end=\"\")\n",
        "  print(items,max(predictions[index].tolist()))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Boy akash 0.9970390796661377\n",
            "Boy vivek 0.9968423843383789\n",
            "Boy John 0.9490768313407898\n",
            "Girl Laila 0.9929890632629395\n",
            "Girl Samantha 0.9940319657325745\n",
            "Boy Rohit 0.9195820689201355\n",
            "Boy Sam 0.9956364035606384\n",
            "Boy Jupiter 0.9774627685546875\n",
            "Girl Shiliqua 0.995093584060669\n",
            "Girl Eileen 0.9929437041282654\n",
            "Girl Kasey 0.9810515642166138\n",
            "Girl Casey 0.6886679530143738\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}