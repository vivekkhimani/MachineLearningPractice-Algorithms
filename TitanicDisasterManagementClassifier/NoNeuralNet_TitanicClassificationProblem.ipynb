{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NoNeuralNet_TitanicClassificationProblem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WiTkW4sCyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler,MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0bLUsOKtfMe",
        "colab_type": "code",
        "outputId": "d33beeaf-ab66-4994-86ec-a8b6072f1cda",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d39d270-26aa-4a9e-83ac-4c4c032a9cba\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5d39d270-26aa-4a9e-83ac-4c4c032a9cba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SubmissionFile.csv to SubmissionFile.csv\n",
            "Saving test.csv to test (1).csv\n",
            "Saving train.csv to train (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV5aunVduMC9",
        "colab_type": "code",
        "outputId": "da7a6b6a-ee39-4593-d94e-327db1346099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "train_values_df = pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
        "submission_values_df = pd.read_csv(io.BytesIO(uploaded['test.csv']))\n",
        "\n",
        "\n",
        "#Balancing Classes\n",
        "df_majority = train_values_df[train_values_df.Survived==0]\n",
        "df_minority = train_values_df[train_values_df.Survived==1]\n",
        "\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=549,    # to match majority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "train_values_df = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "#Dividing Data\n",
        "\n",
        "data_X = train_values_df.iloc [:,[2,4,5,6,7]]\n",
        "data_Y = train_values_df.iloc [:,1].to_numpy()\n",
        "\n",
        "submission_X = submission_values_df.iloc[:,[1,3,4,5,6]]\n",
        "\n",
        "\n",
        "#Checking for class imbalance\n",
        "counter_0,counter_1 = 0,0\n",
        "for vals in data_Y:\n",
        "  if vals == 0:\n",
        "    counter_0+=1\n",
        "  else:\n",
        "    counter_1+=1\n",
        "  \n",
        "print(counter_0,counter_1)\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "data_X = data_X.apply(label_encoder.fit_transform)\n",
        "scaler.fit(data_X[['Age']])\n",
        "age_vector = scaler.transform(data_X[['Age']])\n",
        "data_X['Age'] = age_vector\n",
        "\n",
        "\n",
        "submission_X = submission_X.apply(label_encoder.fit_transform)\n",
        "scaler.fit(submission_X[['Age']])\n",
        "sub_age_vector = scaler.transform(submission_X[['Age']])\n",
        "submission_X['Age'] = sub_age_vector\n",
        "\n",
        "\n",
        "#Updated array to fit One Hot Encoder\n",
        "label_encoder_fit_array = pd.concat([data_X,submission_X])\n",
        "label_encoder_fit_array = label_encoder_fit_array.to_numpy()\n",
        "\n",
        "#Converting individual to numpy arrays after combining completed above\n",
        "data_X = data_X.to_numpy()\n",
        "submission_X = submission_X.to_numpy()\n",
        "\n",
        "\n",
        "#Updated One Hot Encoding\n",
        "my_encoder_X = OneHotEncoder(categorical_features = [0,1,3,4])\n",
        "my_encoder_X.fit(label_encoder_fit_array)\n",
        "data_X_transformed = my_encoder_X.transform(data_X).toarray()\n",
        "submission_transformed = my_encoder_X.transform(submission_X).toarray()\n",
        "\n",
        "\n",
        "#One Hot Encoding\n",
        "#my_encoder_X = OneHotEncoder(categorical_features = [0,1,3,4])\n",
        "#data_X_transformed = my_encoder_X.fit_transform(data_X).toarray()\n",
        "#submission_transformed = my_encoder_X.fit_transform(submission_X).toarray()\n",
        "\n",
        "my_encoder_Y = OneHotEncoder()\n",
        "data_Y_transformed = my_encoder_Y.fit_transform(data_Y.reshape(-1,1)).toarray()\n",
        "\n",
        "\n",
        "#Train_Test_Split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data_X_transformed, data_Y, test_size=0.30, random_state=40)\n",
        "\n",
        "#######ADDRESS THE ISSUE WITH DIFFERENT SIZES OF TRAIN SET AND SUBMISSION SET BECAUSE OF A MISSING DATA POINT WITH SPECIFIC CLASS VALUE IN ONE OF THE FEATURES ---> This causes difference in shape! #######\n",
        "print(data_X_transformed.shape)\n",
        "#print(data_X_transformed)\n",
        "print(submission_transformed.shape)\n",
        "#print(submission_transformed)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "549 549\n",
            "(1098, 21)\n",
            "(418, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k24QQRtj_4Si",
        "colab_type": "code",
        "outputId": "75b73db9-2fc1-429e-bec1-01665f76b968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Logistic Regression\n",
        "logistic_regression = LogisticRegression(solver='lbfgs', penalty=\"none\", fit_intercept=False)\n",
        "\n",
        "logistic_regression.fit(X_train,Y_train)\n",
        "predictions = logistic_regression.predict(X_test)\n",
        "score = accuracy_score(predictions,Y_test) * 100\n",
        "print(score)\n",
        "print(classification_report(predictions,Y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       184\n",
            "           1       0.74      0.84      0.79       146\n",
            "\n",
            "    accuracy                           0.80       330\n",
            "   macro avg       0.80      0.80      0.80       330\n",
            "weighted avg       0.81      0.80      0.80       330\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yQrdRX-qNaX",
        "colab_type": "code",
        "outputId": "1ff59b68-1571-4e6e-ad01-1187ff626596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Decision Tree\n",
        "decision_tree = DecisionTreeClassifier(random_state=0, criterion='gini',max_depth=5, class_weight = 'balanced')\n",
        "\n",
        "decision_tree.fit(X_train,Y_train)\n",
        "predictions = decision_tree.predict(X_test)\n",
        "score = accuracy_score(predictions,Y_test) * 100\n",
        "print(score)\n",
        "print(classification_report(predictions,Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79.39393939393939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       186\n",
            "           1       0.73      0.83      0.78       144\n",
            "\n",
            "    accuracy                           0.79       330\n",
            "   macro avg       0.79      0.80      0.79       330\n",
            "weighted avg       0.80      0.79      0.79       330\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJRd1Kna9qC",
        "colab_type": "code",
        "outputId": "ec72c685-50e1-4691-e69f-018d1620de0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Submission File Preparation\n",
        "\n",
        "#Writing Logistic Regression Results on the Submission CSV file. \n",
        "logistic_regression = LogisticRegression(solver='lbfgs', penalty=\"none\", fit_intercept=False)\n",
        "logistic_regression.fit(X_train,Y_train)\n",
        "predictions = logistic_regression.predict(submission_transformed)\n",
        "#print(prob_pred)\n",
        "\n",
        "output_list = []\n",
        "with open('SubmissionFile.csv') as csv_file:\n",
        "  reader = csv.reader(csv_file)\n",
        "  output_list = list(reader)\n",
        "csv_file.close()\n",
        "\n",
        "\n",
        "pred_list = predictions.tolist()\n",
        "print(pred_list)\n",
        "\n",
        "output_list[0].append('Survived')\n",
        "counter = 1\n",
        "for items in pred_list:\n",
        "  output_list[counter].append(items)\n",
        "  counter+=1\n",
        "  \n",
        "print(output_list)\n",
        "\n",
        "\n",
        "#writing output list to csv_file\n",
        "with open(\"FinalFile.csv\",'w') as csv_file:\n",
        "  writer = csv.writer(csv_file)\n",
        "  writer.writerows(output_list)\n",
        "csv_file.close()\n",
        "\n",
        "#files.download(\"FinalFile.csv\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n",
            "[['PassengerId', 'Survived'], ['892', 0], ['893', 1], ['894', 0], ['895', 0], ['896', 1], ['897', 0], ['898', 1], ['899', 0], ['900', 1], ['901', 0], ['902', 0], ['903', 0], ['904', 1], ['905', 0], ['906', 1], ['907', 1], ['908', 0], ['909', 0], ['910', 1], ['911', 1], ['912', 1], ['913', 0], ['914', 1], ['915', 1], ['916', 1], ['917', 0], ['918', 1], ['919', 0], ['920', 0], ['921', 0], ['922', 0], ['923', 0], ['924', 1], ['925', 1], ['926', 1], ['927', 0], ['928', 1], ['929', 1], ['930', 0], ['931', 0], ['932', 0], ['933', 0], ['934', 0], ['935', 1], ['936', 1], ['937', 0], ['938', 0], ['939', 0], ['940', 1], ['941', 1], ['942', 1], ['943', 0], ['944', 1], ['945', 1], ['946', 0], ['947', 0], ['948', 0], ['949', 0], ['950', 0], ['951', 1], ['952', 0], ['953', 0], ['954', 0], ['955', 1], ['956', 1], ['957', 1], ['958', 1], ['959', 0], ['960', 0], ['961', 0], ['962', 1], ['963', 0], ['964', 1], ['965', 0], ['966', 1], ['967', 0], ['968', 0], ['969', 1], ['970', 0], ['971', 1], ['972', 0], ['973', 1], ['974', 0], ['975', 0], ['976', 0], ['977', 0], ['978', 1], ['979', 1], ['980', 1], ['981', 0], ['982', 1], ['983', 0], ['984', 1], ['985', 0], ['986', 0], ['987', 0], ['988', 1], ['989', 0], ['990', 1], ['991', 0], ['992', 1], ['993', 0], ['994', 0], ['995', 0], ['996', 1], ['997', 0], ['998', 0], ['999', 0], ['1000', 0], ['1001', 0], ['1002', 0], ['1003', 1], ['1004', 1], ['1005', 1], ['1006', 1], ['1007', 0], ['1008', 0], ['1009', 1], ['1010', 0], ['1011', 1], ['1012', 1], ['1013', 0], ['1014', 1], ['1015', 0], ['1016', 0], ['1017', 1], ['1018', 0], ['1019', 0], ['1020', 0], ['1021', 0], ['1022', 0], ['1023', 0], ['1024', 0], ['1025', 0], ['1026', 0], ['1027', 0], ['1028', 0], ['1029', 0], ['1030', 1], ['1031', 0], ['1032', 0], ['1033', 1], ['1034', 0], ['1035', 0], ['1036', 0], ['1037', 0], ['1038', 0], ['1039', 0], ['1040', 0], ['1041', 0], ['1042', 1], ['1043', 0], ['1044', 0], ['1045', 1], ['1046', 0], ['1047', 0], ['1048', 1], ['1049', 1], ['1050', 0], ['1051', 1], ['1052', 1], ['1053', 0], ['1054', 1], ['1055', 0], ['1056', 0], ['1057', 1], ['1058', 0], ['1059', 0], ['1060', 1], ['1061', 1], ['1062', 0], ['1063', 0], ['1064', 0], ['1065', 0], ['1066', 0], ['1067', 1], ['1068', 1], ['1069', 1], ['1070', 1], ['1071', 1], ['1072', 0], ['1073', 1], ['1074', 1], ['1075', 0], ['1076', 1], ['1077', 0], ['1078', 1], ['1079', 0], ['1080', 0], ['1081', 0], ['1082', 0], ['1083', 0], ['1084', 0], ['1085', 0], ['1086', 0], ['1087', 0], ['1088', 1], ['1089', 1], ['1090', 0], ['1091', 1], ['1092', 1], ['1093', 0], ['1094', 1], ['1095', 1], ['1096', 0], ['1097', 0], ['1098', 1], ['1099', 0], ['1100', 1], ['1101', 0], ['1102', 0], ['1103', 0], ['1104', 0], ['1105', 1], ['1106', 0], ['1107', 0], ['1108', 1], ['1109', 1], ['1110', 1], ['1111', 0], ['1112', 1], ['1113', 0], ['1114', 1], ['1115', 0], ['1116', 1], ['1117', 1], ['1118', 0], ['1119', 1], ['1120', 0], ['1121', 0], ['1122', 0], ['1123', 1], ['1124', 0], ['1125', 0], ['1126', 1], ['1127', 0], ['1128', 1], ['1129', 0], ['1130', 1], ['1131', 1], ['1132', 1], ['1133', 1], ['1134', 1], ['1135', 0], ['1136', 0], ['1137', 1], ['1138', 1], ['1139', 0], ['1140', 1], ['1141', 1], ['1142', 1], ['1143', 0], ['1144', 1], ['1145', 0], ['1146', 0], ['1147', 0], ['1148', 0], ['1149', 0], ['1150', 1], ['1151', 0], ['1152', 0], ['1153', 0], ['1154', 1], ['1155', 1], ['1156', 0], ['1157', 0], ['1158', 0], ['1159', 0], ['1160', 1], ['1161', 0], ['1162', 0], ['1163', 0], ['1164', 1], ['1165', 1], ['1166', 0], ['1167', 1], ['1168', 0], ['1169', 0], ['1170', 0], ['1171', 0], ['1172', 1], ['1173', 0], ['1174', 1], ['1175', 1], ['1176', 1], ['1177', 0], ['1178', 0], ['1179', 1], ['1180', 0], ['1181', 0], ['1182', 0], ['1183', 1], ['1184', 0], ['1185', 1], ['1186', 0], ['1187', 0], ['1188', 1], ['1189', 0], ['1190', 0], ['1191', 0], ['1192', 0], ['1193', 0], ['1194', 0], ['1195', 0], ['1196', 1], ['1197', 1], ['1198', 1], ['1199', 0], ['1200', 1], ['1201', 1], ['1202', 0], ['1203', 0], ['1204', 0], ['1205', 1], ['1206', 1], ['1207', 1], ['1208', 1], ['1209', 0], ['1210', 0], ['1211', 0], ['1212', 0], ['1213', 0], ['1214', 0], ['1215', 0], ['1216', 1], ['1217', 0], ['1218', 1], ['1219', 0], ['1220', 0], ['1221', 0], ['1222', 1], ['1223', 0], ['1224', 0], ['1225', 1], ['1226', 0], ['1227', 0], ['1228', 0], ['1229', 0], ['1230', 0], ['1231', 0], ['1232', 0], ['1233', 0], ['1234', 0], ['1235', 1], ['1236', 0], ['1237', 1], ['1238', 0], ['1239', 1], ['1240', 0], ['1241', 1], ['1242', 1], ['1243', 0], ['1244', 0], ['1245', 0], ['1246', 1], ['1247', 0], ['1248', 1], ['1249', 0], ['1250', 0], ['1251', 1], ['1252', 0], ['1253', 1], ['1254', 1], ['1255', 0], ['1256', 1], ['1257', 0], ['1258', 0], ['1259', 1], ['1260', 1], ['1261', 0], ['1262', 0], ['1263', 1], ['1264', 0], ['1265', 0], ['1266', 1], ['1267', 1], ['1268', 1], ['1269', 0], ['1270', 0], ['1271', 0], ['1272', 0], ['1273', 0], ['1274', 1], ['1275', 1], ['1276', 0], ['1277', 1], ['1278', 0], ['1279', 0], ['1280', 0], ['1281', 0], ['1282', 1], ['1283', 1], ['1284', 0], ['1285', 0], ['1286', 0], ['1287', 1], ['1288', 0], ['1289', 1], ['1290', 0], ['1291', 0], ['1292', 1], ['1293', 0], ['1294', 1], ['1295', 1], ['1296', 1], ['1297', 0], ['1298', 0], ['1299', 1], ['1300', 1], ['1301', 1], ['1302', 1], ['1303', 1], ['1304', 1], ['1305', 0], ['1306', 1], ['1307', 0], ['1308', 0], ['1309', 0]]\n",
            "419\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}